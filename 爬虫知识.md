## 爬虫tips
* 限速--构建Throttle
* 用户代理
* 重复请求500类错误
* 设置代理header
* urlparse.urljoin构建绝对路径
* robotparser解析robots.txt
* 爬虫深度陷阱

## 抓取tips
* 规范化：使用lxml时，先把html解析为统一格式(已经废除这种方法，直接使用lxml.etree.HTML即可)
* 使用类的__call__方法构建回调类

## 缓存
<!---->
	文件名长度有限制，
	linux文件名最长255字节, 	
	win文件名最长255字符
	
	且文件数量也有限制，
	fat32系统限制单个目录最多文件数65535，
	ext4系统限制为1500万个

* 磁盘缓存容易实现，但是缺点是收到本地文件系统限制
* 使用nosql更合适，推荐mongodb

## 解析html

- 一个好用法	`etree.HTML(html.decode())`，可以防止莫名其妙的编码错误

## 表单
- 优秀模块 `mechanize`

## 验证码处理

- 优秀模块 `pytesseract`
- 二值化
- 腐蚀阈值文本
- 图片大小调节
- 训练数据
- 限制结果为单词、数字等
- 打码工具
	
	

## 背景调研
* robots.txt
* 检查网站地图
* 查询whois